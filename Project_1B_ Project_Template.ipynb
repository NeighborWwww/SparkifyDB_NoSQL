{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the csv files has been created in current folder, this part of the code can be skipped.\n",
    "\n",
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print(file_path_list)\n",
    "print(len(file_path_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster\n",
    "\n",
    "This should make a connection to a Cassandra instance your local machine, generate a session to execute queries \n",
    "\n",
    "This program require cassandra package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace\n",
    "\n",
    "Generate a keyspace called sparkify if not exists in apache cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"CREATE KEYSPACE IF NOT EXISTS sparkify \n",
    "    WITH REPLICATION = \n",
    "    {'class' : 'SimpleStrategy', 'replication_factor' : 1}\"\"\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('sparkify')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1. We need to provide the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4\n",
    "\n",
    "##### Step 1.\n",
    "Create a table called songInfo if not exists. This table has sessionId (varint), itemInSession (varint), artist (text), firstName (text), song (text), length (float). To select record with sessionId = 338, and itemInSession = 4, we choose sessionid and itemInSession as partition keys.\n",
    "\n",
    "##### Step 2.\n",
    "Import the data from .csv file. using INSERT query to insert corresponding data from the .csv files. Following the order of the table. change the data type of input data if necessary.\n",
    "\n",
    "##### Step 3.\n",
    "Using SELECT queries to get artist, song, length for the table for userid = 10 and sessionid = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create1 = \"CREATE TABLE IF NOT EXISTS songInfo \"\n",
    "createquery1 = create1 + \"(sessionId varint, itemInSession varint, artist text, firstName text, song text, length float, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "try:\n",
    "    session.execute(createquery1)\n",
    "except Exception as e:\n",
    "    print(\"False to create the songInfo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment and Run the block below to drop the table only if mistakes happened in insert. Then modify and create the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fa789b4ce90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#session.execute(\"DROP TABLE IF EXISTS songInfo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## add the information to the table\n",
    "        #print(line)\n",
    "        query = \"INSERT INTO songInfo (sessionId, itemInSession, artist, firstName, song, length)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[1], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Faithless', song='Music Matters (Mark Knight Dub)', length=495.30731201171875)\n"
     ]
    }
   ],
   "source": [
    "## Using select to exam if the table is contain right information.\n",
    "result1 = session.execute(\"\"\"SELECT artist, song, length FROM songInfo WHERE sessionId = 338 AND itemInSession = 4\"\"\")\n",
    "\n",
    "for result in result1:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2. We need to list artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182. \n",
    "\n",
    "##### Step 1.\n",
    "Create a table called listenlist if not exists. This table has sessionId (varint), userId (varint), itemInSession (varint), artist (text), song (text), firstName (text), lastName (text). We need to use userid and sessionid to perform select, so userid and sessionid are chosen as partition key. and the result should be sorted by itemInSession. So we set the itemInSession as clustering column. \n",
    "\n",
    "##### Step 2.\n",
    "Import the data from .csv file. using INSERT query to insert corresponding data from the .csv files. Following the order of the table. change the data type of input data if necessary.\n",
    "\n",
    "##### Step 3.\n",
    "Using SELECT queries to get artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment and Run the block below to drop the table only if mistakes happened in insert. Then modify and create the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session.execute(\"DROP TABLE IF EXISTS listenlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Down To The Bone', song=\"Keep On Keepin' On\", firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Three Drives', song='Greece 2000', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Sebastien Tellier', song='Kilometer', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Lonnie Gordon', song='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', firstname='Sylvie', lastname='Cruz')\n"
     ]
    }
   ],
   "source": [
    "create2 = \"CREATE TABLE IF NOT EXISTS listenlist \"\n",
    "createquery2 = create2 + \"(sessionId varint, userId varint, itemInSession varint, artist text, song text, \\\n",
    "                        firstName text, lastName text, PRIMARY KEY ((sessionId, userId), itemInSession))\"\n",
    "try:\n",
    "    session.execute(createquery2)\n",
    "except Exception as e:\n",
    "    print(\"False to create the listenlist\")\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        #print(line)\n",
    "        query = \"INSERT INTO listenlist (sessionId, userId, itemInSession, artist, song, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[10]), int(line[3]), line[0], line[9], line[1], line[4]))\n",
    "        \n",
    "result1 = session.execute(\"\"\"SELECT artist, song, firstName, lastName FROM listenlist \\\n",
    "                            WHERE sessionId = 182 AND userId = 10\"\"\")\n",
    "\n",
    "for result in result1:\n",
    "    print(result)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3. We need to select every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "##### Step 1.\n",
    "Create a table called listener if not exists. This table has song (text), userId (varint), firstName (text), lastName (text). To select the listener of a certain song, we need to select the song and userId as the partition key. \n",
    "\n",
    "##### Step 2.\n",
    "Import the data from .csv file. using INSERT query to insert corresponding data from the .csv files. Following the order of the table. change the data type of input data if necessary.\n",
    "\n",
    "##### Step 3.\n",
    "Using SELECT queries to get firstName, lastName for the listener of All Hands Against His Own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment and Run the block below to drop the table only if mistakes happened in insert. Then modify and create the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fa78be9d710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#session.execute(\"DROP TABLE IF EXISTS listener\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(firstname='Jacqueline', lastname='Lynch')\n",
      "Row(firstname='Tegan', lastname='Levine')\n",
      "Row(firstname='Sara', lastname='Johnson')\n"
     ]
    }
   ],
   "source": [
    "create3 = \"CREATE TABLE IF NOT EXISTS listener \"\n",
    "createquery3 = create3 + \"(song text, userId varint, firstName text, lastName text, PRIMARY KEY (song, userId))\"\n",
    "try:\n",
    "    session.execute(createquery3)\n",
    "except Exception as e:\n",
    "    print(\"False to create the listener\")\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        #print(line)\n",
    "        query = \"INSERT INTO listener (song, userId, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))\n",
    "        \n",
    "result1 = session.execute(\"\"\"SELECT firstName, lastName FROM listener WHERE song = 'All Hands Against His Own'\"\"\")\n",
    "\n",
    "for result in result1:\n",
    "    print(result)     \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fa789b54090>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# queries to drop the tables\n",
    "\n",
    "session.execute(\"DROP TABLE IF EXISTS songInfo\")\n",
    "session.execute(\"DROP TABLE IF EXISTS listenlist\")\n",
    "session.execute(\"DROP TABLE IF EXISTS listener\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutdown the session and the cluster\n",
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
